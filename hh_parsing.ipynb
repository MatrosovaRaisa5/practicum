{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9cc48-8c7d-4e94-8051-d13d37b5b0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas requests aiohttp pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c887e926-8972-4bcd-b675-60de953714e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d726cb0f-963d-4ca1-b3a4-250385cd28e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from beautifulsoup4) (4.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d050692-9cff-4610-b98a-e0c01161c150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be26cef8-28a7-46cd-99d0-4bc779df94e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: click in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from nltk) (2025.9.18)\n",
      "Requirement already satisfied: tqdm in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\zver\\desktop\\machine_learning\\venv\\lib\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "879d4b95-241b-4e86-a85a-159549bc1d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Начало сбора данных через публичное API\n",
      "Получение списка вакансий...\n",
      "Страница 1: получено 50 вакансий\n",
      "Страница 2: получено 50 вакансий\n",
      "Страница 3: получено 50 вакансий\n",
      "Страница 4: получено 50 вакансий\n",
      "Страница 5: получено 50 вакансий\n",
      "Страница 6: получено 50 вакансий\n",
      "Страница 7: получено 50 вакансий\n",
      "Страница 8: получено 50 вакансий\n",
      "Страница 9: получено 50 вакансий\n",
      "Страница 10: получено 50 вакансий\n",
      "Найдено вакансий: 500\n",
      "Получение деталей вакансий...\n",
      "Обработано 10/500 вакансий\n",
      "Обработано 20/500 вакансий\n",
      "Обработано 30/500 вакансий\n",
      "Обработано 40/500 вакансий\n",
      "Обработано 50/500 вакансий\n",
      "Обработано 60/500 вакансий\n",
      "Обработано 70/500 вакансий\n",
      "Обработано 80/500 вакансий\n",
      "Обработано 90/500 вакансий\n",
      "Обработано 100/500 вакансий\n",
      "Обработано 110/500 вакансий\n",
      "Обработано 120/500 вакансий\n",
      "Обработано 130/500 вакансий\n",
      "Обработано 140/500 вакансий\n",
      "Обработано 150/500 вакансий\n",
      "Обработано 160/500 вакансий\n",
      "Обработано 170/500 вакансий\n",
      "Обработано 180/500 вакансий\n",
      "Обработано 190/500 вакансий\n",
      "Обработано 200/500 вакансий\n",
      "Обработано 210/500 вакансий\n",
      "Обработано 220/500 вакансий\n",
      "Обработано 230/500 вакансий\n",
      "Обработано 240/500 вакансий\n",
      "Обработано 250/500 вакансий\n",
      "Обработано 260/500 вакансий\n",
      "Обработано 270/500 вакансий\n",
      "Обработано 280/500 вакансий\n",
      "Обработано 290/500 вакансий\n",
      "Обработано 300/500 вакансий\n",
      "Обработано 310/500 вакансий\n",
      "Обработано 320/500 вакансий\n",
      "Обработано 330/500 вакансий\n",
      "Обработано 340/500 вакансий\n",
      "Обработано 350/500 вакансий\n",
      "Обработано 360/500 вакансий\n",
      "Обработано 370/500 вакансий\n",
      "Обработано 380/500 вакансий\n",
      "Обработано 390/500 вакансий\n",
      "Обработано 400/500 вакансий\n",
      "Обработано 410/500 вакансий\n",
      "Обработано 420/500 вакансий\n",
      "Обработано 430/500 вакансий\n",
      "Обработано 440/500 вакансий\n",
      "Обработано 450/500 вакансий\n",
      "Обработано 460/500 вакансий\n",
      "Обработано 470/500 вакансий\n",
      "Обработано 480/500 вакансий\n",
      "Обработано 490/500 вакансий\n",
      "Обработано 500/500 вакансий\n",
      "Собрано: 500 вакансий\n",
      "Датасет сохранен в data\\hh_vacancies_2025-10-12_22-25.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "EMAIL = \"matrosova-05@list.ru\"\n",
    "\n",
    "# Функция для получения id вакансий\n",
    "def fetch_vacancies_ids(search_text=\"python\", area=1, per_page=50, pages=10):\n",
    "    ids = []\n",
    "    base_url = \"https://api.hh.ru/vacancies\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': f'MyApp ({EMAIL})'\n",
    "    }\n",
    "    \n",
    "    for page in range(pages):\n",
    "        params = {\n",
    "            'text': search_text,\n",
    "            'area': area,\n",
    "            'per_page': per_page,\n",
    "            'page': page\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(base_url, params=params, headers=headers)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                for item in data['items']:\n",
    "                    ids.append(item['id'])\n",
    "                print(f\"Страница {page + 1}: получено {len(data['items'])} вакансий\")\n",
    "            else:\n",
    "                print(f\"Ошибка при запросе страницы {page}: {response.status_code}\")\n",
    "                if response.status_code == 403:\n",
    "                    print(\"Доступ запрещен\")\n",
    "                print(response.text)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Исключение при запросе страницы {page}: {str(e)}\")\n",
    "        \n",
    "        # Задержка м/у запросами\n",
    "        time.sleep(2)\n",
    "        \n",
    "    return ids\n",
    "\n",
    "# Функция для получения деталей вакансии \n",
    "def fetch_vacancy_details(vacancy_id):\n",
    "    url = f\"https://api.hh.ru/vacancies/{vacancy_id}\"\n",
    "    \n",
    "    headers = {\n",
    "        'User-Agent': f'MyApp ({EMAIL})'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            vacancy_data = response.json()\n",
    "            \n",
    "            description = parse_description(vacancy_data)\n",
    "            \n",
    "            vacancy_info = {\n",
    "                'id': vacancy_data.get('id'),\n",
    "                'name': vacancy_data.get('name'),\n",
    "                'salary': vacancy_data.get('salary'),\n",
    "                'area': vacancy_data.get('area', {}).get('name') if vacancy_data.get('area') else None,\n",
    "                'published_at': vacancy_data.get('published_at'),\n",
    "                'employer': vacancy_data.get('employer', {}).get('name') if vacancy_data.get('employer') else None,\n",
    "                'experience': vacancy_data.get('experience', {}).get('name') if vacancy_data.get('experience') else None,\n",
    "                'employment': vacancy_data.get('employment', {}).get('name') if vacancy_data.get('employment') else None,\n",
    "                'description': description,\n",
    "                'key_skills': [skill['name'] for skill in vacancy_data.get('key_skills', [])],\n",
    "                'schedule': vacancy_data.get('schedule', {}).get('name') if vacancy_data.get('schedule') else None,\n",
    "                'professional_roles': [role['name'] for role in vacancy_data.get('professional_roles', [])],\n",
    "                'url': vacancy_data.get('alternate_url')\n",
    "            }\n",
    "            \n",
    "            return vacancy_info\n",
    "        else:\n",
    "            print(f\"Ошибка при запросе вакансии {vacancy_id}: {response.status_code}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Исключение при обработке вакансии {vacancy_id}: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    finally:\n",
    "        time.sleep(1)\n",
    "\n",
    "# Очистка\n",
    "def parse_description(vacancy_data):\n",
    "    description = vacancy_data.get('description')\n",
    "    if not description:\n",
    "        return ''\n",
    "\n",
    "    soup = BeautifulSoup(description, 'html.parser')\n",
    "    clean_text = soup.get_text(separator=' ')  # Убираем html теги\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()  # Убираем лишние пробелы и переносы строк\n",
    "    return clean_text\n",
    "\n",
    "# Основная многопоточная функция\n",
    "def main_threaded():\n",
    "    print(\"Начало сбора данных через публичное API\")\n",
    "    \n",
    "    print(\"Получение списка вакансий...\")\n",
    "    vacancy_ids = fetch_vacancies_ids(pages=10)\n",
    "    print(f\"Найдено вакансий: {len(vacancy_ids)}\")\n",
    "\n",
    "    if not vacancy_ids:\n",
    "        print(\"Не удалось получить список вакансий\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    vacancies_details = []\n",
    "    print(\"Получение деталей вакансий...\")\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "        futures = [executor.submit(fetch_vacancy_details, vid) for vid in vacancy_ids]\n",
    "        \n",
    "        for i, future in enumerate(as_completed(futures)):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                vacancies_details.append(result)\n",
    "            \n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Обработано {i + 1}/{len(vacancy_ids)} вакансий\")\n",
    "    \n",
    "    df = pd.DataFrame(vacancies_details)\n",
    "    print(f\"Собрано: {len(df)} вакансий\")\n",
    "    \n",
    "    # Сохраняем\n",
    "    data_folder = \"data\"\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    \n",
    "    csv_filename = os.path.join(data_folder, f\"hh_vacancies_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\")\n",
    "    df.to_csv(csv_filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Датасет сохранен в {csv_filename}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = main_threaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f339b584-81aa-4530-a036-fcb26b981d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработанный датасет сохранен в processed_hh_vacancies_2025-10-12_22-25.csv\n",
      "\n",
      "Размер датасета: (500, 13)\n",
      "\n",
      "Столбцы: ['ID', 'Название_вакансии', 'Зарплата', 'Город', 'Дата_публикации', 'Работодатель', 'Опыт', 'Тип_занятости', 'Описание', 'Ключевые_навыки', 'График', 'Профессиональные_роли', 'Ссылка']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def process_dataset(df):\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    def format_salary(salary):\n",
    "        if pd.isna(salary) or salary == '' or salary == 'None':\n",
    "            return 'Не указана'\n",
    "        \n",
    "        # Если salary это строка, попробуем преобразовать в словарь\n",
    "        if isinstance(salary, str):\n",
    "            try:\n",
    "                salary = ast.literal_eval(salary)\n",
    "            except:\n",
    "                return 'Не указана'\n",
    "        \n",
    "        if isinstance(salary, dict):\n",
    "            parts = []\n",
    "            if salary.get('from'):\n",
    "                parts.append(f\"от {salary['from']}\")\n",
    "            if salary.get('to'):\n",
    "                parts.append(f\"до {salary['to']}\")\n",
    "            \n",
    "            if not parts:\n",
    "                return 'Не указана'\n",
    "            \n",
    "            currency = salary.get('currency', '')\n",
    "            currency_map = {\n",
    "                'RUR': 'руб.',\n",
    "                'RUB': 'руб.', \n",
    "                'USD': '$',\n",
    "                'EUR': '€',\n",
    "                'KZT': 'тенге'\n",
    "            }\n",
    "            \n",
    "            currency_str = currency_map.get(currency, currency)\n",
    "            result = ' '.join(parts)\n",
    "            if currency_str:\n",
    "                result += f' {currency_str}'\n",
    "            \n",
    "            gross = salary.get('gross')\n",
    "            if gross is not None:\n",
    "                result += ' (до вычета налогов)' if gross else ' (на руки)'\n",
    "            \n",
    "            return result\n",
    "        else:\n",
    "            return 'Не указана'\n",
    "    \n",
    "    df_processed['salary'] = df_processed['salary'].apply(format_salary)\n",
    "    \n",
    "    # Обработка столбца key_skills\n",
    "    def format_skills(skills):\n",
    "        if pd.isna(skills) or skills == '' or skills == '[]':\n",
    "            return ''\n",
    "        \n",
    "        if isinstance(skills, str):\n",
    "            try:\n",
    "                # Пробуем преобразовать строку в список\n",
    "                skills_list = ast.literal_eval(skills)\n",
    "                if isinstance(skills_list, list):\n",
    "                    return ', '.join(skills_list)\n",
    "            except:\n",
    "                # Если не получается, очищаем строку\n",
    "                skills = re.sub(r'[\\[\\]\\'\\\"]', '', skills)\n",
    "                return skills\n",
    "        elif isinstance(skills, list):\n",
    "            return ', '.join(skills)\n",
    "        else:\n",
    "            return str(skills)\n",
    "    \n",
    "    df_processed['key_skills'] = df_processed['key_skills'].apply(format_skills)\n",
    "    \n",
    "    # Обработка столбца professional_roles\n",
    "    def format_roles(roles):\n",
    "        if pd.isna(roles) or roles == '' or roles == '[]':\n",
    "            return ''\n",
    "        \n",
    "        if isinstance(roles, str):\n",
    "            try:\n",
    "                roles_list = ast.literal_eval(roles)\n",
    "                if isinstance(roles_list, list):\n",
    "                    return ', '.join(roles_list)\n",
    "            except:\n",
    "                roles = re.sub(r'[\\[\\]\\'\\\"]', '', roles)\n",
    "                return roles\n",
    "        elif isinstance(roles, list):\n",
    "            return ', '.join(roles)\n",
    "        else:\n",
    "            return str(roles)\n",
    "    \n",
    "    df_processed['professional_roles'] = df_processed['professional_roles'].apply(format_roles)\n",
    "    \n",
    "    # Обработка даты - оставляем только дату без времени\n",
    "    def format_date(date_str):\n",
    "        if pd.isna(date_str) or date_str == '':\n",
    "            return ''\n",
    "        \n",
    "        if isinstance(date_str, str):\n",
    "            return date_str[:10] if len(date_str) >= 10 else date_str\n",
    "        else:\n",
    "            return str(date_str)\n",
    "    \n",
    "    df_processed['published_at'] = df_processed['published_at'].apply(format_date)\n",
    "    \n",
    "    # Очистка описания от лишних пробелов\n",
    "    def clean_description(desc):\n",
    "        if pd.isna(desc) or desc == '':\n",
    "            return ''\n",
    "        \n",
    "        # Заменяем множественные пробелы и переносы на один пробел\n",
    "        cleaned = re.sub(r'\\s+', ' ', str(desc)).strip()\n",
    "        return cleaned\n",
    "    \n",
    "    df_processed['description'] = df_processed['description'].apply(clean_description)\n",
    "    \n",
    "    # Переименовываем столбцы\n",
    "    column_rename = {\n",
    "        'id': 'ID',\n",
    "        'name': 'Название_вакансии',\n",
    "        'salary': 'Зарплата',\n",
    "        'area': 'Город',\n",
    "        'published_at': 'Дата_публикации',\n",
    "        'employer': 'Работодатель',\n",
    "        'experience': 'Опыт',\n",
    "        'employment': 'Тип_занятости',\n",
    "        'description': 'Описание',\n",
    "        'key_skills': 'Ключевые_навыки',\n",
    "        'schedule': 'График',\n",
    "        'professional_roles': 'Профессиональные_роли',\n",
    "        'url': 'Ссылка'\n",
    "    }\n",
    "    \n",
    "    df_processed = df_processed.rename(columns=column_rename)\n",
    "    \n",
    "    # Упорядочиваем столбцы\n",
    "    column_order = [\n",
    "        'ID', 'Название_вакансии', 'Зарплата', 'Город', 'Дата_публикации',\n",
    "        'Работодатель', 'Опыт', 'Тип_занятости', 'Описание', 'Ключевые_навыки',\n",
    "        'График', 'Профессиональные_роли', 'Ссылка'\n",
    "    ]\n",
    "    \n",
    "    existing_columns = [col for col in column_order if col in df_processed.columns]\n",
    "    df_processed = df_processed[existing_columns]\n",
    "    \n",
    "    return df_processed\n",
    "\n",
    "def save_processed_dataset(df, filename=None):\n",
    "\n",
    "    data_folder = \"data\"\n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = f\"processed_hh_vacancies_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.csv\"\n",
    "    else:\n",
    "        filename = os.path.join(data_folder, filename)\n",
    "    \n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Обработанный датасет сохранен в {filename}\")\n",
    "    return filename\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    original_file = \"data/hh_vacancies_2025-10-12_22-25.csv\" \n",
    "    df_original = pd.read_csv(original_file, encoding='utf-8-sig')\n",
    "    \n",
    "    df_processed = process_dataset(df_original)\n",
    "    \n",
    "    save_processed_dataset(df_processed)\n",
    "    \n",
    "    print(f\"\\nРазмер датасета: {df_processed.shape}\")\n",
    "    print(f\"\\nСтолбцы: {list(df_processed.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0c6662c-ce16-457c-bdbb-c39cc5311fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(r'C:\\Users\\Zver\\Desktop\\machine_learning\\notebook\\nlp\\data\\processed_hh_vacancies_2025-10-12_22-25.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef3c4fa5-37e4-4fe5-ab52-ae48a135fc87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Название_вакансии</th>\n",
       "      <th>Зарплата</th>\n",
       "      <th>Город</th>\n",
       "      <th>Дата_публикации</th>\n",
       "      <th>Работодатель</th>\n",
       "      <th>Опыт</th>\n",
       "      <th>Тип_занятости</th>\n",
       "      <th>Описание</th>\n",
       "      <th>Ключевые_навыки</th>\n",
       "      <th>График</th>\n",
       "      <th>Профессиональные_роли</th>\n",
       "      <th>Ссылка</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>125797603</td>\n",
       "      <td>Middle Backend разработчик (R&amp;D / Startup-прое...</td>\n",
       "      <td>Не указана</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>Aiti Guru</td>\n",
       "      <td>От 1 года до 3 лет</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>В связи с ростом компании и запуском новых про...</td>\n",
       "      <td>JavaScript, Python, REST, SQL, Git, HTML, Разр...</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>Программист, разработчик</td>\n",
       "      <td>https://hh.ru/vacancy/125797603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>125158150</td>\n",
       "      <td>Data Scientist/ ML Engineer в направление LLM</td>\n",
       "      <td>Не указана</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2025-10-10</td>\n",
       "      <td>X5 Tech</td>\n",
       "      <td>От 3 до 6 лет</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>X5 Group — российская розничная торговая компа...</td>\n",
       "      <td>Python, Машинное обучение</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>Дата-сайентист</td>\n",
       "      <td>https://hh.ru/vacancy/125158150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>124880155</td>\n",
       "      <td>Head of Python Development</td>\n",
       "      <td>Не указана</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>Хантфлоу</td>\n",
       "      <td>Более 6 лет</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Хантфлоу — главный инструмент работы рекрутеро...</td>\n",
       "      <td>Python, FastAPI, PostgreSQL, Tornado, TechLead</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>Программист, разработчик</td>\n",
       "      <td>https://hh.ru/vacancy/124880155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>123761902</td>\n",
       "      <td>Разработчик Python (Серверная Астра)</td>\n",
       "      <td>Не указана</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2025-10-06</td>\n",
       "      <td>Группа компаний Астра</td>\n",
       "      <td>От 3 до 6 лет</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Мы группа компаний «Астра» – один из лидеров р...</td>\n",
       "      <td>Linux, Python</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>Программист, разработчик</td>\n",
       "      <td>https://hh.ru/vacancy/123761902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>126174282</td>\n",
       "      <td>Риск-менеджер / Инвестиционный аналитик (Junio...</td>\n",
       "      <td>до 100000 руб. (на руки)</td>\n",
       "      <td>Москва</td>\n",
       "      <td>2025-10-12</td>\n",
       "      <td>ADF Capital</td>\n",
       "      <td>От 1 года до 3 лет</td>\n",
       "      <td>Полная занятость</td>\n",
       "      <td>Привет! Мы ADF Capital — инновационная проп-тр...</td>\n",
       "      <td>Анализ рисков, Аналитическое мышление, SQL, Оц...</td>\n",
       "      <td>Полный день</td>\n",
       "      <td>Финансовый менеджер</td>\n",
       "      <td>https://hh.ru/vacancy/126174282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                                  Название_вакансии  \\\n",
       "149  125797603  Middle Backend разработчик (R&D / Startup-прое...   \n",
       "243  125158150      Data Scientist/ ML Engineer в направление LLM   \n",
       "84   124880155                         Head of Python Development   \n",
       "102  123761902               Разработчик Python (Серверная Астра)   \n",
       "206  126174282  Риск-менеджер / Инвестиционный аналитик (Junio...   \n",
       "\n",
       "                     Зарплата   Город Дата_публикации           Работодатель  \\\n",
       "149                Не указана  Москва      2025-10-10              Aiti Guru   \n",
       "243                Не указана  Москва      2025-10-10                X5 Tech   \n",
       "84                 Не указана  Москва      2025-10-12               Хантфлоу   \n",
       "102                Не указана  Москва      2025-10-06  Группа компаний Астра   \n",
       "206  до 100000 руб. (на руки)  Москва      2025-10-12            ADF Capital   \n",
       "\n",
       "                   Опыт     Тип_занятости  \\\n",
       "149  От 1 года до 3 лет  Полная занятость   \n",
       "243       От 3 до 6 лет  Полная занятость   \n",
       "84          Более 6 лет  Полная занятость   \n",
       "102       От 3 до 6 лет  Полная занятость   \n",
       "206  От 1 года до 3 лет  Полная занятость   \n",
       "\n",
       "                                              Описание  \\\n",
       "149  В связи с ростом компании и запуском новых про...   \n",
       "243  X5 Group — российская розничная торговая компа...   \n",
       "84   Хантфлоу — главный инструмент работы рекрутеро...   \n",
       "102  Мы группа компаний «Астра» – один из лидеров р...   \n",
       "206  Привет! Мы ADF Capital — инновационная проп-тр...   \n",
       "\n",
       "                                       Ключевые_навыки            График  \\\n",
       "149  JavaScript, Python, REST, SQL, Git, HTML, Разр...       Полный день   \n",
       "243                          Python, Машинное обучение       Полный день   \n",
       "84      Python, FastAPI, PostgreSQL, Tornado, TechLead  Удаленная работа   \n",
       "102                                      Linux, Python  Удаленная работа   \n",
       "206  Анализ рисков, Аналитическое мышление, SQL, Оц...       Полный день   \n",
       "\n",
       "        Профессиональные_роли                           Ссылка  \n",
       "149  Программист, разработчик  https://hh.ru/vacancy/125797603  \n",
       "243            Дата-сайентист  https://hh.ru/vacancy/125158150  \n",
       "84   Программист, разработчик  https://hh.ru/vacancy/124880155  \n",
       "102  Программист, разработчик  https://hh.ru/vacancy/123761902  \n",
       "206       Финансовый менеджер  https://hh.ru/vacancy/126174282  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb62ae7-bd28-4fea-91bf-cd266720b0ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdf0955-0388-4e61-93ca-d03d999644d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
